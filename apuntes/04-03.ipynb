{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regresión Logística"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ejemplo "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Resultados con ajuste manual de hiperparámetros:\n",
      "Accuracy: 79.87%\n",
      "Precision: 78.26%\n",
      "Recall: 63.16%\n",
      "F1-Score: 69.90%\n",
      "AUC-ROC: 85.89%\n",
      "\n",
      "Resultados con ajuste automático de hiperparámetros:\n",
      "Mejores parámetros: {'C': 1, 'solver': 'liblinear'}\n",
      "Mejor Accuracy en validación cruzada: 76.51%\n",
      "Accuracy: 81.17%\n",
      "Precision: 79.17%\n",
      "Recall: 66.67%\n",
      "F1-Score: 72.38%\n",
      "AUC-ROC: 86.15%\n",
      "\n",
      "Resultados con Sobremuestreo Aleatorio:\n",
      "Accuracy: 77.92%\n",
      "Precision: 67.16%\n",
      "Recall: 78.95%\n",
      "F1-Score: 72.58%\n",
      "AUC-ROC: 86.04%\n",
      "\n",
      "Resultados con SMOTE:\n",
      "Accuracy: 79.87%\n",
      "Precision: 70.97%\n",
      "Recall: 77.19%\n",
      "F1-Score: 73.95%\n",
      "AUC-ROC: 86.34%\n",
      "\n",
      "Resultados con Submuestreo Aleatorio:\n",
      "Accuracy: 75.32%\n",
      "Precision: 64.18%\n",
      "Recall: 75.44%\n",
      "F1-Score: 69.35%\n",
      "AUC-ROC: 85.24%\n",
      "\n",
      "Resultados con NearMiss:\n",
      "Accuracy: 75.32%\n",
      "Precision: 64.18%\n",
      "Recall: 75.44%\n",
      "F1-Score: 69.35%\n",
      "AUC-ROC: 85.69%\n",
      "\n",
      "El mejor método de balanceo es: SMOTE con F1-Score: 73.95% y AUC-ROC: 86.34%\n",
      "           Real    Predicción\n",
      "0  No Diabético  No Diabético\n",
      "1  No Diabético  No Diabético\n",
      "2  No Diabético  No Diabético\n",
      "3  No Diabético  No Diabético\n",
      "4  No Diabético  No Diabético\n",
      "5  No Diabético  No Diabético\n",
      "6  No Diabético  No Diabético\n",
      "7     Diabético  No Diabético\n",
      "8  No Diabético     Diabético\n",
      "9  No Diabético  No Diabético\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from imblearn.over_sampling import RandomOverSampler, SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler, NearMiss\n",
    "\n",
    "# Cargar datos\n",
    "df = pd.read_csv(\"https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.data.csv\")\n",
    "X = df.iloc[:, :-1]\n",
    "y = df.iloc[:, -1]\n",
    "\n",
    "# Preprocesamiento\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# Dividir en entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# --------------------\n",
    "# MÉTODOS DE BALANCEO DE CLASES\n",
    "# --------------------\n",
    "# 1. Sobremuestreo aleatorio\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "X_train_ros, y_train_ros = ros.fit_resample(X_train, y_train)\n",
    "\n",
    "# 2. SMOTE (Synthetic Minority Over-sampling Technique)\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# 3. Submuestreo aleatorio\n",
    "rus = RandomUnderSampler(random_state=42)\n",
    "X_train_rus, y_train_rus = rus.fit_resample(X_train, y_train)\n",
    "\n",
    "# 4. NearMiss (submuestreo basado en distancia)\n",
    "nearmiss = NearMiss()\n",
    "X_train_nm, y_train_nm = nearmiss.fit_resample(X_train, y_train)\n",
    "\n",
    "# --------------------\n",
    "# MÉTODO 1: Ajuste manual de hiperparámetros\n",
    "# --------------------\n",
    "manual_model = LogisticRegression(C=0.1, solver='liblinear', max_iter=500)  # Hiperparámetros ajustados manualmente\n",
    "manual_model.fit(X_train, y_train)  # Entrenar modelo\n",
    "\n",
    "# Predicciones\n",
    "y_pred_manual = manual_model.predict(X_test)\n",
    "\n",
    "# Evaluación del modelo ajustado manualmente\n",
    "print(\"\\nResultados con ajuste manual de hiperparámetros:\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred_manual) * 100:.2f}%\")\n",
    "print(f\"Precision: {precision_score(y_test, y_pred_manual) * 100:.2f}%\")\n",
    "print(f\"Recall: {recall_score(y_test, y_pred_manual) * 100:.2f}%\")\n",
    "print(f\"F1-Score: {f1_score(y_test, y_pred_manual) * 100:.2f}%\")\n",
    "print(f\"AUC-ROC: {roc_auc_score(y_test, manual_model.predict_proba(X_test)[:,1]) * 100:.2f}%\")\n",
    "\n",
    "# --------------------\n",
    "# MÉTODO 2: Ajuste automático con GridSearchCV\n",
    "# --------------------\n",
    "parametros = {\n",
    "    \"C\": [0.001, 0.01, 0.1, 1, 10, 100],  # Diferentes valores de regularización\n",
    "    \"solver\": [\"liblinear\", \"lbfgs\"]  # Diferentes algoritmos de optimización\n",
    "}\n",
    "\n",
    "# Configurar GridSearchCV\n",
    "grid_search = GridSearchCV(LogisticRegression(max_iter=500), parametros, cv=5, scoring=\"accuracy\", n_jobs=-1)\n",
    "\n",
    "grid_search.fit(X_train, y_train)  # Entrenar búsqueda de hiperparámetros\n",
    "\n",
    "# Mejor modelo encontrado\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Predicciones del mejor modelo\n",
    "y_pred_best = best_model.predict(X_test)\n",
    "\n",
    "# Evaluación del mejor modelo\n",
    "print(\"\\nResultados con ajuste automático de hiperparámetros:\")\n",
    "print(f\"Mejores parámetros: {grid_search.best_params_}\")\n",
    "print(f\"Mejor Accuracy en validación cruzada: {grid_search.best_score_ * 100:.2f}%\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred_best) * 100:.2f}%\")\n",
    "print(f\"Precision: {precision_score(y_test, y_pred_best) * 100:.2f}%\")\n",
    "print(f\"Recall: {recall_score(y_test, y_pred_best) * 100:.2f}%\")\n",
    "print(f\"F1-Score: {f1_score(y_test, y_pred_best) * 100:.2f}%\")\n",
    "print(f\"AUC-ROC: {roc_auc_score(y_test, best_model.predict_proba(X_test)[:,1]) * 100:.2f}%\")\n",
    "\n",
    "\n",
    "# --------------------\n",
    "# EVALUACIÓN DE MÉTODOS DE BALANCEO\n",
    "# --------------------\n",
    "resultados_balanceo = {}\n",
    "\n",
    "def evaluar_balanceo(X_train_resampled, y_train_resampled, metodo):\n",
    "    model = LogisticRegression(C=0.1, solver='liblinear', max_iter=500)\n",
    "    model.fit(X_train_resampled, y_train_resampled)\n",
    "    y_pred = model.predict(X_test)\n",
    "    f1 = f1_score(y_test, y_pred) * 100\n",
    "    auc = roc_auc_score(y_test, model.predict_proba(X_test)[:,1]) * 100\n",
    "    resultados_balanceo[metodo] = (f1, auc)\n",
    "    print(f\"\\nResultados con {metodo}:\")\n",
    "    print(f\"Accuracy: {accuracy_score(y_test, y_pred) * 100:.2f}%\")\n",
    "    print(f\"Precision: {precision_score(y_test, y_pred) * 100:.2f}%\")\n",
    "    print(f\"Recall: {recall_score(y_test, y_pred) * 100:.2f}%\")\n",
    "    print(f\"F1-Score: {f1:.2f}%\")\n",
    "    print(f\"AUC-ROC: {auc:.2f}%\")\n",
    "\n",
    "evaluar_balanceo(X_train_ros, y_train_ros, \"Sobremuestreo Aleatorio\")\n",
    "evaluar_balanceo(X_train_smote, y_train_smote, \"SMOTE\")\n",
    "evaluar_balanceo(X_train_rus, y_train_rus, \"Submuestreo Aleatorio\")\n",
    "evaluar_balanceo(X_train_nm, y_train_nm, \"NearMiss\")\n",
    "\n",
    "# Seleccionar el mejor método de balanceo\n",
    "mejor_metodo = max(resultados_balanceo, key=lambda k: resultados_balanceo[k])\n",
    "print(f\"\\nEl mejor método de balanceo es: {mejor_metodo} con F1-Score: {resultados_balanceo[mejor_metodo][0]:.2f}% y AUC-ROC: {resultados_balanceo[mejor_metodo][1]:.2f}%\")\n",
    "\n",
    "# Obtener los datos balanceados del mejor método encontrado\n",
    "if mejor_metodo == \"Sobremuestreo Aleatorio\":\n",
    "    X_train_resampled, y_train_resampled = X_train_ros, y_train_ros\n",
    "elif mejor_metodo == \"SMOTE\":\n",
    "    X_train_resampled, y_train_resampled = X_train_smote, y_train_smote\n",
    "elif mejor_metodo == \"Submuestreo Aleatorio\":\n",
    "    X_train_resampled, y_train_resampled = X_train_rus, y_train_rus\n",
    "elif mejor_metodo == \"NearMiss\":\n",
    "    X_train_resampled, y_train_resampled = X_train_nm, y_train_nm\n",
    "\n",
    "# --------------------\n",
    "# ENTRENAMIENTO FINAL Y EVALUACIÓN\n",
    "# --------------------\n",
    "\n",
    "# Entrenar el mejor modelo con los datos balanceados\n",
    "best_model.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Realizar predicciones finales con el mejor modelo y el mejor balanceo\n",
    "y_pred_final = best_model.predict(X_test)\n",
    "\n",
    "# Crear DataFrame de resultados\n",
    "resultados = pd.DataFrame({\n",
    "    \"Real\": y_test.values,\n",
    "    \"Predicción\": y_pred_final\n",
    "})\n",
    "\n",
    "# Mapear valores 0 y 1 a etiquetas comprensibles\n",
    "resultados[\"Real\"] = resultados[\"Real\"].map({0: \"No Diabético\", 1: \"Diabético\"})\n",
    "resultados[\"Predicción\"] = resultados[\"Predicción\"].map({0: \"No Diabético\", 1: \"Diabético\"})\n",
    "\n",
    "# Mostrar las primeras filas de la tabla\n",
    "print(resultados.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DF despues de OneHotEncoder\n",
      "      Age  Speed_of_Impact  Survived  Gender_Female  Gender_Male  \\\n",
      "0     56             27.0         1           True        False   \n",
      "1     69             46.0         1           True        False   \n",
      "2     46             46.0         0          False         True   \n",
      "3     32            117.0         0          False         True   \n",
      "4     60             40.0         0           True        False   \n",
      "..   ...              ...       ...            ...          ...   \n",
      "195   69            111.0         1           True        False   \n",
      "196   30             51.0         1           True        False   \n",
      "197   58            110.0         1          False         True   \n",
      "198   20            103.0         1          False         True   \n",
      "199   56             43.0         1           True        False   \n",
      "\n",
      "     Helmet_Used_No  Helmet_Used_Yes  Seatbelt_Used_No  Seatbelt_Used_Yes  \n",
      "0              True            False              True              False  \n",
      "1              True            False             False               True  \n",
      "2             False             True             False               True  \n",
      "3              True            False             False               True  \n",
      "4             False             True             False               True  \n",
      "..              ...              ...               ...                ...  \n",
      "195            True            False             False               True  \n",
      "196            True            False             False               True  \n",
      "197            True            False             False               True  \n",
      "198            True            False             False               True  \n",
      "199            True            False             False               True  \n",
      "\n",
      "[200 rows x 9 columns]\n",
      "DF despues de LabelEncoder\n",
      "      Age  Gender  Speed_of_Impact  Helmet_Used  Seatbelt_Used  Survived\n",
      "0     56       0             27.0            0              0         1\n",
      "1     69       0             46.0            0              1         1\n",
      "2     46       1             46.0            1              1         0\n",
      "3     32       1            117.0            0              1         0\n",
      "4     60       0             40.0            1              1         0\n",
      "..   ...     ...              ...          ...            ...       ...\n",
      "195   69       0            111.0            0              1         1\n",
      "196   30       0             51.0            0              1         1\n",
      "197   58       1            110.0            0              1         1\n",
      "198   20       1            103.0            0              1         1\n",
      "199   56       0             43.0            0              1         1\n",
      "\n",
      "[200 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "df = pd.read_csv(\"../csvs/accident.csv\")\n",
    "\n",
    "#Definición de variables y preprocesamiento con One-Hot-Encoding\n",
    "df_codif = pd.get_dummies(df)\n",
    "X = df_codif.drop(df_codif[\"Survived\"])\n",
    "y = df_codif['Survived']\n",
    "print(\"DF despues de OneHotEncoder\\n\", df_codif)\n",
    "#print(df_codif.columns)\n",
    "\n",
    "#Definición de variables y preprocesamiento con LabelEncoder\n",
    "encoder = LabelEncoder()\n",
    "df['Gender'] = encoder.fit_transform(df['Gender'])\n",
    "df['Helmet_Used'] = encoder.fit_transform(df['Helmet_Used'])\n",
    "df['Seatbelt_Used'] = encoder.fit_transform(df['Seatbelt_Used'])\n",
    "\n",
    "X = df.drop(df[\"Survived\"])\n",
    "y = df['Survived']\n",
    "print(\"DF despues de LabelEncoder\\n\", df)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "#Ahora habría que pasar estos datos divididos por cada uno de los métodos de balanceo de clases.\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
