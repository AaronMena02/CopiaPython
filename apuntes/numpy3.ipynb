{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id  ventas  media_ventas\n",
      "0   1   10842       20393.6\n",
      "1   2   32183       20393.6\n",
      "2   3    2416       20393.6\n",
      "3   4   33858       20393.6\n",
      "4   5   29370       20393.6\n",
      "5   6    2675       20393.6\n",
      "6   7   28965       20393.6\n",
      "7   8    7452       20393.6\n",
      "8   9   35537       20393.6\n",
      "9  10   20638       20393.6\n",
      "   id  ventas  media_ventas  mediana_ventas\n",
      "0   1   10842       20393.6         24801.5\n",
      "1   2   32183       20393.6         24801.5\n",
      "2   3    2416       20393.6         24801.5\n",
      "3   4   33858       20393.6         24801.5\n",
      "4   5   29370       20393.6         24801.5\n",
      "5   6    2675       20393.6         24801.5\n",
      "6   7   28965       20393.6         24801.5\n",
      "7   8    7452       20393.6         24801.5\n",
      "8   9   35537       20393.6         24801.5\n",
      "9  10   20638       20393.6         24801.5\n",
      "   id  ventas  media_ventas  mediana_ventas  desviacion_ventas\n",
      "0   1   10842       20393.6         24801.5       13331.532922\n",
      "1   2   32183       20393.6         24801.5       13331.532922\n",
      "2   3    2416       20393.6         24801.5       13331.532922\n",
      "3   4   33858       20393.6         24801.5       13331.532922\n",
      "4   5   29370       20393.6         24801.5       13331.532922\n",
      "5   6    2675       20393.6         24801.5       13331.532922\n",
      "6   7   28965       20393.6         24801.5       13331.532922\n",
      "7   8    7452       20393.6         24801.5       13331.532922\n",
      "8   9   35537       20393.6         24801.5       13331.532922\n",
      "9  10   20638       20393.6         24801.5       13331.532922\n",
      "   id  ventas  media_ventas  mediana_ventas  desviacion_ventas  \\\n",
      "0   1   10842       20393.6         24801.5       13331.532922   \n",
      "1   2   32183       20393.6         24801.5       13331.532922   \n",
      "2   3    2416       20393.6         24801.5       13331.532922   \n",
      "3   4   33858       20393.6         24801.5       13331.532922   \n",
      "4   5   29370       20393.6         24801.5       13331.532922   \n",
      "5   6    2675       20393.6         24801.5       13331.532922   \n",
      "6   7   28965       20393.6         24801.5       13331.532922   \n",
      "7   8    7452       20393.6         24801.5       13331.532922   \n",
      "8   9   35537       20393.6         24801.5       13331.532922   \n",
      "9  10   20638       20393.6         24801.5       13331.532922   \n",
      "\n",
      "   ventas_normalizadas  \n",
      "0            -0.716467  \n",
      "1             0.884324  \n",
      "2            -1.348502  \n",
      "3             1.009966  \n",
      "4             0.673321  \n",
      "5            -1.329074  \n",
      "6             0.642942  \n",
      "7            -0.970751  \n",
      "8             1.135908  \n",
      "9             0.018332  \n",
      "valores normalizados con StandScaler de scikit:    valores  valores_normalizados\n",
      "0        1             -1.566699\n",
      "1        2             -1.218544\n",
      "2        3             -0.870388\n",
      "3        4             -0.522233\n",
      "4        5             -0.174078\n",
      "5        6              0.174078\n",
      "6        7              0.522233\n",
      "7        8              0.870388\n",
      "8        9              1.218544\n",
      "9       10              1.566699\n",
      "   valor   z_score\n",
      "0     10 -1.414214\n",
      "1     20 -0.707107\n",
      "2     30  0.000000\n",
      "3     40  0.707107\n",
      "4     50  1.414214\n",
      "   id  ventas  min_ventas  max_ventas\n",
      "0   1   36797       10467       38415\n",
      "1   2   13665       10467       38415\n",
      "2   3   19375       10467       38415\n",
      "3   4   32748       10467       38415\n",
      "4   5   10467       10467       38415\n",
      "5   6   19523       10467       38415\n",
      "6   7   14737       10467       38415\n",
      "7   8   16133       10467       38415\n",
      "8   9   30342       10467       38415\n",
      "9  10   38415       10467       38415\n",
      "   id  ventas  min_ventas  max_ventas  percentil_25  percentil_75\n",
      "0   1   36797       10467       38415       15086.0       32146.5\n",
      "1   2   13665       10467       38415       15086.0       32146.5\n",
      "2   3   19375       10467       38415       15086.0       32146.5\n",
      "3   4   32748       10467       38415       15086.0       32146.5\n",
      "4   5   10467       10467       38415       15086.0       32146.5\n",
      "5   6   19523       10467       38415       15086.0       32146.5\n",
      "6   7   14737       10467       38415       15086.0       32146.5\n",
      "7   8   16133       10467       38415       15086.0       32146.5\n",
      "8   9   30342       10467       38415       15086.0       32146.5\n",
      "9  10   38415       10467       38415       15086.0       32146.5\n",
      "DF EJERCICIO:\n",
      "    id  values  min_values  max_values  percentil_25  percentil_50  \\\n",
      "0   1      46          20          46          25.0          34.0   \n",
      "1   2      34          20          46          25.0          34.0   \n",
      "2   3      25          20          46          25.0          34.0   \n",
      "3   4      45          20          46          25.0          34.0   \n",
      "4   5      20          20          46          25.0          34.0   \n",
      "\n",
      "   percentil_80  \n",
      "0          45.2  \n",
      "1          45.2  \n",
      "2          45.2  \n",
      "3          45.2  \n",
      "4          45.2  \n",
      "DF EJERCICIO DEL 1 AL 10:\n",
      "    id  values  min_values  max_values  percentil_25  percentil_50  \\\n",
      "0   1       8           0          10           4.0           6.5   \n",
      "1   2       4           0          10           4.0           6.5   \n",
      "2   3       4           0          10           4.0           6.5   \n",
      "3   4       2           0          10           4.0           6.5   \n",
      "4   5      10           0          10           4.0           6.5   \n",
      "5   6      10           0          10           4.0           6.5   \n",
      "6   7       0           0          10           4.0           6.5   \n",
      "7   8       8           0          10           4.0           6.5   \n",
      "8   9      10           0          10           4.0           6.5   \n",
      "9  10       5           0          10           4.0           6.5   \n",
      "\n",
      "   percentil_80  \n",
      "0          10.0  \n",
      "1          10.0  \n",
      "2          10.0  \n",
      "3          10.0  \n",
      "4          10.0  \n",
      "5          10.0  \n",
      "6          10.0  \n",
      "7          10.0  \n",
      "8          10.0  \n",
      "9          10.0  \n",
      "10.5 952.5000000000002\n",
      "[[-1. ]\n",
      " [-0.6]\n",
      " [-0.2]\n",
      " [ 0.2]\n",
      " [ 0.6]\n",
      " [38.6]]\n",
      "   id  ventas  min_ventas  max_ventas  percentil_25  percentil_75 categoria  \\\n",
      "0   1   36797       10467       38415       15086.0       32146.5         C   \n",
      "1   2   13665       10467       38415       15086.0       32146.5         B   \n",
      "2   3   19375       10467       38415       15086.0       32146.5         B   \n",
      "3   4   32748       10467       38415       15086.0       32146.5         A   \n",
      "4   5   10467       10467       38415       15086.0       32146.5         A   \n",
      "5   6   19523       10467       38415       15086.0       32146.5         C   \n",
      "6   7   14737       10467       38415       15086.0       32146.5         C   \n",
      "7   8   16133       10467       38415       15086.0       32146.5         B   \n",
      "8   9   30342       10467       38415       15086.0       32146.5         C   \n",
      "9  10   38415       10467       38415       15086.0       32146.5         A   \n",
      "\n",
      "   conteo_categorias  \n",
      "0                  4  \n",
      "1                  3  \n",
      "2                  3  \n",
      "3                  3  \n",
      "4                  3  \n",
      "5                  4  \n",
      "6                  4  \n",
      "7                  3  \n",
      "8                  4  \n",
      "9                  3  \n",
      "   id  ventas  min_ventas  max_ventas  percentil_25  percentil_75 categoria  \\\n",
      "0   1   36797       10467       38415       15086.0       32146.5         C   \n",
      "1   2   13665       10467       38415       15086.0       32146.5         B   \n",
      "2   3   19375       10467       38415       15086.0       32146.5         B   \n",
      "3   4   32748       10467       38415       15086.0       32146.5         A   \n",
      "4   5   10467       10467       38415       15086.0       32146.5         A   \n",
      "5   6   19523       10467       38415       15086.0       32146.5         C   \n",
      "6   7   14737       10467       38415       15086.0       32146.5         C   \n",
      "7   8   16133       10467       38415       15086.0       32146.5         B   \n",
      "8   9   30342       10467       38415       15086.0       32146.5         C   \n",
      "9  10   38415       10467       38415       15086.0       32146.5         A   \n",
      "\n",
      "   conteo_categorias  promedio_ventas  \n",
      "0                  4         25349.75  \n",
      "1                  3         16391.00  \n",
      "2                  3         16391.00  \n",
      "3                  3         27210.00  \n",
      "4                  3         27210.00  \n",
      "5                  4         25349.75  \n",
      "6                  4         25349.75  \n",
      "7                  3         16391.00  \n",
      "8                  4         25349.75  \n",
      "9                  3         27210.00  \n",
      "   id  ventas  min_ventas  max_ventas  percentil_25  percentil_75 categoria  \\\n",
      "0   1   36797       10467       38415       15086.0       32146.5         C   \n",
      "1   2   13665       10467       38415       15086.0       32146.5         B   \n",
      "2   3   19375       10467       38415       15086.0       32146.5         B   \n",
      "3   4   32748       10467       38415       15086.0       32146.5         A   \n",
      "4   5   10467       10467       38415       15086.0       32146.5         A   \n",
      "5   6   19523       10467       38415       15086.0       32146.5         C   \n",
      "6   7   14737       10467       38415       15086.0       32146.5         C   \n",
      "7   8   16133       10467       38415       15086.0       32146.5         B   \n",
      "8   9   30342       10467       38415       15086.0       32146.5         C   \n",
      "9  10   38415       10467       38415       15086.0       32146.5         A   \n",
      "\n",
      "   conteo_categorias  promedio_ventas  ventas_normalizadas  \n",
      "0                  4         25349.75             1.000000  \n",
      "1                  3         16391.00             0.000000  \n",
      "2                  3         16391.00             1.000000  \n",
      "3                  3         27210.00             0.797231  \n",
      "4                  3         27210.00             0.000000  \n",
      "5                  4         25349.75             0.216954  \n",
      "6                  4         25349.75             0.000000  \n",
      "7                  3         16391.00             0.432224  \n",
      "8                  4         25349.75             0.707389  \n",
      "9                  3         27210.00             1.000000  \n",
      "   id  ventas  min_ventas  max_ventas  percentil_25  percentil_75 categoria  \\\n",
      "0   1   36797       10467       38415       15086.0       32146.5         C   \n",
      "1   2   13665       10467       38415       15086.0       32146.5         B   \n",
      "2   3   19375       10467       38415       15086.0       32146.5         B   \n",
      "3   4   32748       10467       38415       15086.0       32146.5         A   \n",
      "4   5   10467       10467       38415       15086.0       32146.5         A   \n",
      "5   6   19523       10467       38415       15086.0       32146.5         C   \n",
      "6   7   14737       10467       38415       15086.0       32146.5         C   \n",
      "7   8   16133       10467       38415       15086.0       32146.5         B   \n",
      "8   9   30342       10467       38415       15086.0       32146.5         C   \n",
      "9  10   38415       10467       38415       15086.0       32146.5         A   \n",
      "\n",
      "   conteo_categorias  promedio_ventas  ventas_normalizadas categoria_ventas  \n",
      "0                  4         25349.75             1.000000             Alto  \n",
      "1                  3         16391.00             0.000000             Alto  \n",
      "2                  3         16391.00             1.000000             Alto  \n",
      "3                  3         27210.00             0.797231             Alto  \n",
      "4                  3         27210.00             0.000000             Alto  \n",
      "5                  4         25349.75             0.216954             Alto  \n",
      "6                  4         25349.75             0.000000             Alto  \n",
      "7                  3         16391.00             0.432224             Alto  \n",
      "8                  4         25349.75             0.707389             Alto  \n",
      "9                  3         27210.00             1.000000             Alto  \n",
      "   id  ventas  min_ventas  max_ventas  percentil_25  percentil_75 categoria  \\\n",
      "0   1   36797       10467       38415       15086.0       32146.5         C   \n",
      "1   2   13665       10467       38415       15086.0       32146.5         B   \n",
      "2   3   19375       10467       38415       15086.0       32146.5         B   \n",
      "3   4   32748       10467       38415       15086.0       32146.5         A   \n",
      "4   5   10467       10467       38415       15086.0       32146.5         A   \n",
      "5   6   19523       10467       38415       15086.0       32146.5         C   \n",
      "6   7   14737       10467       38415       15086.0       32146.5         C   \n",
      "7   8   16133       10467       38415       15086.0       32146.5         B   \n",
      "8   9   30342       10467       38415       15086.0       32146.5         C   \n",
      "9  10   38415       10467       38415       15086.0       32146.5         A   \n",
      "\n",
      "   conteo_categorias  promedio_ventas  ventas_normalizadas categoria_ventas  \\\n",
      "0                  4         25349.75             1.000000             Alto   \n",
      "1                  3         16391.00             0.000000             Alto   \n",
      "2                  3         16391.00             1.000000             Alto   \n",
      "3                  3         27210.00             0.797231             Alto   \n",
      "4                  3         27210.00             0.000000             Alto   \n",
      "5                  4         25349.75             0.216954             Alto   \n",
      "6                  4         25349.75             0.000000             Alto   \n",
      "7                  3         16391.00             0.432224             Alto   \n",
      "8                  4         25349.75             0.707389             Alto   \n",
      "9                  3         27210.00             1.000000             Alto   \n",
      "\n",
      "       iqr  \n",
      "0  17060.5  \n",
      "1  17060.5  \n",
      "2  17060.5  \n",
      "3  17060.5  \n",
      "4  17060.5  \n",
      "5  17060.5  \n",
      "6  17060.5  \n",
      "7  17060.5  \n",
      "8  17060.5  \n",
      "9  17060.5  \n",
      "   ingresos       grupo\n",
      "0      1000        bajo\n",
      "1      2000        bajo\n",
      "2      5000  medio-bajo\n",
      "3     10000  medio-alto\n",
      "4     50000        alto\n",
      "5    100000        alto\n",
      "   ingresos       grupo\n",
      "0      1000        bajo\n",
      "1      2000        bajo\n",
      "2      5000  medio-bajo\n",
      "3     10000  medio-alto\n",
      "4     50000        alto\n",
      "5    100000        alto\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ingresos</th>\n",
       "      <th>grupo</th>\n",
       "      <th>nulos_por_fila</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000</td>\n",
       "      <td>bajo</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2000</td>\n",
       "      <td>bajo</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5000</td>\n",
       "      <td>medio-bajo</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10000</td>\n",
       "      <td>medio-alto</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50000</td>\n",
       "      <td>alto</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>100000</td>\n",
       "      <td>alto</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ingresos       grupo  nulos_por_fila\n",
       "0      1000        bajo               0\n",
       "1      2000        bajo               0\n",
       "2      5000  medio-bajo               0\n",
       "3     10000  medio-alto               0\n",
       "4     50000        alto               0\n",
       "5    100000        alto               0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Crear un DataFrame con valores aleatorios\n",
    "df = pd.DataFrame({\n",
    "    \"id\": range(1, 11),\n",
    "    \"ventas\": np.random.randint(100, 40000, size=10)  # Números aleatorios entre 100 y 1000\n",
    "})\n",
    "\n",
    "# MEDIA: Valor promedio de una serie de datos\n",
    "\n",
    "# Agregar una columna con la media de 'ventas'\n",
    "df[\"media_ventas\"] = df[\"ventas\"].mean()\n",
    "print(df)\n",
    "\n",
    "# CALCULAR LA MEDIANA: Valor central de una serie de datos ordenados de menor a mayor\n",
    "\n",
    "df[\"mediana_ventas\"] = df[\"ventas\"].median() # .median() devuelve el valor central de la distribución.\n",
    "print(df)\n",
    "\n",
    "\n",
    "# CALCULAR LA DESVIACIÓN ESTÁNDAR\n",
    "\n",
    "df[\"desviacion_ventas\"] = df[\"ventas\"].std() #.std() calcula la dispersión de los datos respecto a la media.\n",
    "print(df)\n",
    "\n",
    "# NORMALIZAR VALORES CON MEDIA Y DESVIACIÓN ESTÁNDAR \n",
    "\n",
    "df[\"ventas_normalizadas\"] = (df[\"ventas\"] - df[\"ventas\"].mean()) / df[\"ventas\"].std() # Se aplica la fórmula de normalización Z-score: (X - media) / desviación estándar\n",
    "print(df)\n",
    "\n",
    "# --> QUE LA MEDIA SEA IGUAL A CERO\n",
    "# --> QUE LA DESVIACIÓN ESTÁNDAR SEA IGUAL A UNO\n",
    "\n",
    "# Otras formas de aplicar el Z-Score\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#Datos de ejemplo\n",
    "df = pd.DataFrame({\"valores\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]})\n",
    "\n",
    "# Crear un objeto StandardScaler (escalador)\n",
    "scaler = StandardScaler()\n",
    "\n",
    "#Aplicar esta normalización Z-Score\n",
    "df[\"valores_normalizados\"] = scaler.fit_transform(df[[\"valores\"]])\n",
    "\n",
    "print(\"valores normalizados con StandScaler de scikit:\", df)\n",
    "\n",
    "from scipy.stats import zscore\n",
    "import pandas as pd\n",
    "\n",
    "# Datos de ejemplo\n",
    "df = pd.DataFrame({\"valor\": [10, 20, 30, 40, 50]})\n",
    "\n",
    "# Calcular el z-score\n",
    "df[\"z_score\"] = zscore(df[\"valor\"])\n",
    "\n",
    "print(df)\n",
    "\n",
    "\n",
    "# Miniejercicio: Crea una nueva columna, que contenga la media de la columna ventas_normalizadas, y otra columna con la desviación estándar de la columna ventas_normalizadas.\n",
    "\n",
    "# OBTENER EL MÁXIMO Y MÍNIMO DE UNA SERIE\n",
    "\n",
    "# Crear un DataFrame con valores aleatorios\n",
    "df = pd.DataFrame({\n",
    "    \"id\": range(1, 11),\n",
    "    \"ventas\": np.random.randint(100, 40000, size=10)  # Números aleatorios entre 100 y 1000\n",
    "})\n",
    "\n",
    "df[\"min_ventas\"] = df[\"ventas\"].min() # Obtiene el valor más bajo.\n",
    "df[\"max_ventas\"] = df[\"ventas\"].max() # Obtiene el valor más alto.\n",
    "print(df)\n",
    "\n",
    "# CALCULAR PERCENTILES: Obtener el percentil 25 y 75 de la columna \"ventas\". Los percentiles son valores que dividen un conjunto de datos en 100 partes iguales. Cada percentil representa el valor debajo del cual cae un cierto porcentaje de los datos.\n",
    "\n",
    "df[\"percentil_25\"] = df[\"ventas\"].quantile(0.25) #.quantile(0.25) devuelve el percentil 25 y .quantile(0.75) el percentil 75.\n",
    "df[\"percentil_75\"] = df[\"ventas\"].quantile(0.75)\n",
    "print(df)\n",
    "\n",
    "#MINIEJERCICIO: Serie de 5 valores aleatorios entre 20 y 50: Busca el percentil 25,50 y 80\n",
    "\n",
    "df_ej = pd.DataFrame({\n",
    "    \"id\": range(1,6),\n",
    "    \"values\": np.random.randint(20,51, size = 5)\n",
    "})\n",
    "\n",
    "df_ej[\"min_values\"] = df_ej[\"values\"].min() \n",
    "df_ej[\"max_values\"] = df_ej[\"values\"].max() \n",
    "df_ej[\"percentil_25\"] = df_ej[\"values\"].quantile(0.25)\n",
    "df_ej[\"percentil_50\"] = df_ej[\"values\"].quantile(0.50)\n",
    "df_ej[\"percentil_80\"] = df_ej[\"values\"].quantile(0.80)\n",
    "\n",
    "print(\"DF EJERCICIO:\\n\",df_ej)\n",
    "\n",
    "\n",
    "df_del1al10 = pd.DataFrame({\n",
    "    \"id\": range(1,11),\n",
    "    \"values\": np.random.randint(0,11, size = 10)\n",
    "})\n",
    "\n",
    "df_del1al10[\"min_values\"] = df_del1al10[\"values\"].min() \n",
    "df_del1al10[\"max_values\"] = df_del1al10[\"values\"].max() \n",
    "df_del1al10[\"percentil_25\"] = df_del1al10[\"values\"].quantile(0.25)\n",
    "df_del1al10[\"percentil_50\"] = df_del1al10[\"values\"].quantile(0.50)\n",
    "df_del1al10[\"percentil_80\"] = df_del1al10[\"values\"].quantile(0.80)\n",
    "\n",
    "print(\"DF EJERCICIO DEL 1 AL 10:\\n\",df_del1al10)\n",
    "\n",
    "# Eliminar outliers con percentiles\n",
    "datos = np.array([10, 20, 30, 40, 50, 1000])  # El 1000 es un valor atípico\n",
    "P1, P99 = np.percentile(datos, [1, 99])  # Calculamos el percentil 1 y 99\n",
    "print(P1, P99)\n",
    "\n",
    "#Normalizar datos con RobustScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from numpy import array\n",
    "\n",
    "datos = array([[10], [20], [30], [40], [50], [1000]])  # El 1000 es un valor atípico\n",
    "scaler = RobustScaler()  # Usa la mediana y percentiles\n",
    "datos_escalados = scaler.fit_transform(datos)\n",
    "print(datos_escalados)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# CONTAR LA CANTIDAD DE VALORES ÚNICOS: Crear una columna con el conteo de valores únicos en una columna categórica.\n",
    "\n",
    "df[\"categoria\"] = np.random.choice([\"A\", \"B\", \"C\"], size=len(df)) #.choice() elige valores aleatorios de una lista.\n",
    "df[\"conteo_categorias\"] = df.groupby(\"categoria\")[\"categoria\"].transform(\"count\") #.transform(\"count\") cuenta la cantidad de valores únicos en la columna.\n",
    "print(df)\n",
    "\n",
    "# OTROS USOS DE TRANSFORM\n",
    "\n",
    "df[\"promedio_ventas\"] = df.groupby(\"categoria\")[\"ventas\"].transform(\"mean\")\n",
    "print(df) #Asigna a cada fila el promedio de ventas por categoría\n",
    "\n",
    "df[\"ventas_normalizadas\"] = df.groupby(\"categoria\")[\"ventas\"].transform(lambda x: (x - x.min()) / (x.max() - x.min()))\n",
    "print(df) #Normaliza las ventas por categoría\n",
    "\n",
    "\n",
    "\n",
    "# APLICAR UNA FUNCIÓN A UNA COLUMNA: Crear una columna con valores categorizados según las ventas.\n",
    "\n",
    "def clasificar_ventas(valor):\n",
    "    if valor < 400:\n",
    "        return \"Bajo\"\n",
    "    elif valor < 700:\n",
    "        return \"Medio\"\n",
    "    else:\n",
    "        return \"Alto\"\n",
    "\n",
    "df[\"categoria_ventas\"] = df[\"ventas\"].apply(clasificar_ventas) #.apply() aplica una función personalizada a cada valor de la columna.\n",
    "\n",
    "print(df)\n",
    "\n",
    "# CALCULAR EL RANGO INTERCUARTÍLICO: Crear una columna con el rango intercuartílico de la columna \"ventas\". El rango intercuartílico es la diferencia entre el percentil 75 y el 25. Sirve para detectar outliers. Se detectan como outliers los valores que están por debajo del percentil 25 menos 1.5 veces el IQR o por encima del percentil 75 más 1.5 veces el IQR.\n",
    "\n",
    "df[\"iqr\"] = df[\"percentil_75\"] - df[\"percentil_25\"] #IQR es la diferencia entre el percentil 75 y el 25.\n",
    "print(df)\n",
    "\n",
    "# Clasificar los datos en categorías según los percentiles\n",
    "df = pd.DataFrame({\"ingresos\": [1000, 2000, 5000, 10000, 50000, 100000]})\n",
    "df[\"grupo\"] = pd.qcut(df[\"ingresos\"], q=4, labels=[\"bajo\", \"medio-bajo\", \"medio-alto\", \"alto\"]) #.qcut() clasifica los datos en cuartiles y asigna etiquetas a cada rango.\n",
    "print(df)\n",
    "\n",
    "# Clasificamos los ingresos en 4 grupos usando percentiles\n",
    "df[\"grupo\"] = pd.qcut(df[\"ingresos\"], q=4, labels=[\"bajo\", \"medio-bajo\", \"medio-alto\", \"alto\"])\n",
    "\n",
    "print(df)\n",
    "\n",
    "pd.cut(df[\"ingresos\"], bins=[0, 10000, 50000, 100000], labels=[\"bajo\", \"medio\", \"alto\"])\n",
    "\n",
    "\n",
    "\n",
    "# CONTAR VALORES NULOS EN CADA COLUMNA\n",
    "\n",
    "df[\"nulos_por_fila\"] = df.isnull().sum(axis=1) #.isnull().sum(axis=1) cuenta los valores nulos en cada fila.\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Operación Estadística  | Definición | Uso en IA y Ciencia de Datos | Ejemplo de Código |\n",
    "|------------------------|------------|------------------------------|-------------------|\n",
    "| **Media (Promedio)**   | Valor promedio de una columna. | Reemplazar valores faltantes, análisis de rendimiento. | `df[\"media_ventas\"] = df[\"ventas\"].mean()` |\n",
    "| **Mediana**            | Valor central cuando los datos están ordenados. | Útil cuando hay valores extremos, análisis financiero. | `df[\"mediana_ventas\"] = df[\"ventas\"].median()` |\n",
    "| **Desviación estándar** | Mide cuánto varían los valores respecto a la media. | Identificar dispersión, riesgo financiero, estabilidad de modelos. | `df[\"desviacion_ventas\"] = df[\"ventas\"].std()` |\n",
    "| **Normalización (Z-score)** | Convierte los valores a una escala donde la media es 0. | Escalar datos en machine learning, análisis de imágenes. | `df[\"ventas_normalizadas\"] = (df[\"ventas\"] - df[\"ventas\"].mean()) / df[\"ventas\"].std()` |\n",
    "| **Valor mínimo y máximo** | Encuentra el menor y mayor valor de la columna. | Detección de anomalías, análisis de clientes. | `df[\"min_ventas\"] = df[\"ventas\"].min(); df[\"max_ventas\"] = df[\"ventas\"].max()` |\n",
    "| **Percentiles**        | Divide los datos en segmentos según su distribución. | Comparar rendimiento, detectar valores extremos. | `df[\"percentil_25\"] = df[\"ventas\"].quantile(0.25)` |\n",
    "| **Conteo de valores únicos** | Cuenta cuántas veces aparece cada categoría. | Análisis de distribución, segmentación de clientes. | `df[\"conteo_categorias\"] = df.groupby(\"categoria\")[\"categoria\"].transform(\"count\")` |\n",
    "| **Funciones personalizadas** | Aplica reglas específicas para transformar datos. | Clasificación de clientes, detección de fraude. | `df[\"categoria_ventas\"] = df[\"ventas\"].apply(lambda x: \"Alto\" if x > 700 else \"Bajo\")` |\n",
    "| **Rango intercuartílico (IQR)** | Diferencia entre percentil 75 y 25 para detectar atípicos. | Identificación de valores anómalos en datasets. | `df[\"iqr\"] = df[\"percentil_75\"] - df[\"percentil_25\"]` |\n",
    "| **Conteo de valores nulos** | Cuenta los valores faltantes en una fila o columna. | Limpieza de datos, análisis de calidad del dataset. | `df[\"nulos_por_fila\"] = df.isnull().sum(axis=1)` |\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
